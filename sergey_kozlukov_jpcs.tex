\documentclass[a4paper]{jpconf}
\usepackage{graphicx}
\usepackage{iopams}
% amsmath defined substack
\usepackage{amsmath}

\usepackage{todonotes}

\begin{document}
\title{The method of similar operators in the study of graph spectra}

\author{Sergey V Kozlukov}

\address{\emph{Voronezh State University}, 1 Universitetskaya Ploshad', Voronezh, RU 394036}

\ead{ithesaboteur@yandex.com}

\begin{abstract}
    The~method~of~similar~operators~\cite{baskakov1983methods,baskakov2014memory,baskakov2017method,baskakov2013completeness}
        is used to investigate spectral properties
        of a certain class of matrices in the context of graphs~\cite{van2003graphs,cvetkovic1980spectra}.
    Specifically, we consider matrices
        obtained as combinations
        of kronecker products~\cite{bellman-matrices-kron}
        and small-norm perturbations.
    The estimates of the spectrum and the eigenvectors
        of such matrices are given.
\end{abstract}

\section{Introduction}
Consider a~directed graph on \( N \) vertices.
Its adjacency matrix is defined as
    a matrix
    \( A = (a_{ij}) \)
    of the size \( N\times N \),
    in which \( a_{ij} \)
    is the number of edges
    from the vertex \( i \)
    to the vertex \( j \).
One can also consider generalized
    adjacency matrices~\cite{van2003graphs}
    which are defined as
    arbitrary linear combinations
    of matrices \( A \) (or its transpose \( A^\mathtt{T} \)),
    \( E \) (identity matrix)
    and \( J \) (the all-ones matrix).
These matrices arise naturally
    in some stochastic models.
The spectral  properties of these matrices
    often play a vital role in such models.
For instance, the markovian random walk on a~graph
    yields the notion of the eigenvector centrality
    in a~network~\cite{bonacich1972factoring}.
The transition matrix of such a random walk
    is a generalized adjacency matrix of the network graph.
The score of the vertex \( i \)
    is defined as the \( i \)'th coordinate
    of the dominating eigenvector
    of the transition matrix.
The largest eigenvalue of the row-stochastic matrix
    is \( 1 \) and the dominating eigenvector
    defines the stationary distribution
    of the random walk.
The PageRank~\cite{ilprints422} algorithm
    originally used by Google
    to compute the eigenvector centrality
    relies on the Power-Method.
The speed of its convergence
    is determined by the ratio
    of the absolute values of
    the two largest eigenvalues
    of the transition matrix.
The stability of the stationary distribution
    is determined~\cite{chakrabarti2008epidemic,wang2003epidemic} by a spectral gap
    which is defined as the difference of
    the two largest absolute eigenvalues.
The method of estimation of almost-invariant sets proposed in~\cite{schwartz2006fluctuation}
    relies as well on the spectral decomposition of such matrices.
In the Susceptible-Infective-Susceptible model
    a viral spread in a network
    is modeled as a markov process
    with \( 2^N \) states.
The asymptotic (endemic or epidemic) behaviour of this system
    is determined by the adjacency matrix spectral radius
    and the rates of curage and infection.
For more details and comprehensive description
    the graph spectra theory
    refer to~\cite{cvetkovic1980spectra,godsil2013algebraic}.

\section{Methods and materials\todo{Shall we really put it as a separate odd-named section?}}

We use the abstract method of similar operators
    to derive estimates of eigenvalues and eigenvectors
    of certain types of such matrices.
First we state the required notation and theorems
    in a simplified form that accounts for finite-dimensionality
    of the problem.
For a more in-depth introduction to the method
    refer to~\cite{baskakov1983methods,baskakov2014memory,baskakov2017method,baskakov2013completeness}.

Let \( \mathbb{K}\in \{ \mathbb{R}, \mathbb{C} \} \)
    be a field of either real or complex numbers.
We consider the vector space \( \mathbb{K}^n,\ n\in \mathbb{N} \)
    to be supplied with euclidian structure:
    \[
        (x, y){=}\sum_k x_k\overline{y_k},
        \ x{=}(x_1,\ldots, x_n),
        \ y=(y_1,\ldots, y_n)
        \in \mathbb{K}^n
        \]
    and the \( \mathrm{L}_2 \) norm:
    \(
        \|x\|_2^2{=}(x,x).
        \)
When \( V_1, V_2 \) are normed vector spaces
    we denote by \( L(V_1, V_2) \)
    the space of bounded linear mappings
    from \( V_1 \) to \( V_2 \).
An algebra of bounded linear endomorphisms
    from a Banach space \( V \)
    into itself
    is denoted by \( L(V) = L(V, V) \).
It is a Banach algebra with the operator norm:
    \[
        \|A\|_{\mathrm{op}} =
        \sup_{\substack{\|x\|=1,\\ x\in V}} \|A x\|,\ A\in L(V).
        \]
Together with \( L(\mathbb{K}^n, \mathbb{K}^m) \)
    we consider its isomorphic space \( \mathbb{K}^{m{\times}n} \)
    of matrices of the size \( m{\times}n \)
    with the entries from the field \( \mathbb{K} \).
The space \( \mathbb{K}^{n{\times}n}\sim L(\mathbb{K}^n) \)
    forms a Banach algebra
    when supplied with one of the following norms:
    \( \|A\|_{\mathrm{op}} = \sup_{\|x\|_2=1,\ x\in \mathbb{K}^n} \|A x\|_2,\ \)
    \( \|A\|_{\mathrm{F}} = \sqrt{\sum_{i,j} |a_{ij}|^2},\ \)
    for a matrix 
    \( A{=}(a_{ij})\in\mathbb{K}^{n\times n} \).
Finally we are going to need isomorphic spaces
    \( L(L(\mathbb{K}^n)) \) and \( L(\mathbb{K}^{n{\times}n}) \)
    with the operator norm.
We will follow {Krein MG\todo{cite smth}}
    and refer to elements of \( L(\mathbb{K}^{n{\times}n}) \)
    as ``transformers''.

The spectrum of a matrix \( A \)
    (the set of its eigenvalues)
    will be denoted as \( \sigma(A) \).
We call two matrices \( A_1, A_2 \) \emph{similar}
    if there is an invertible matrix \( U \)
    (called similarity matrix)
    such that \( A_1 U = U A_2 \).
Similar matrices share some spectral properties:
    they are isospectral (\( \sigma(A_1) = \sigma(A_2) \))
    and \( U \) maps eigenvectors of one to another's:
    \( A_2 x = \lambda x \implies A_1 U x = \lambda U x \).
\section*{References}
\bibliographystyle{iopart-num}
\bibliography{sergey_kozlukov_jpcs}{}
\end{document}
